{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad64c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "XGBoost-Only Product Pricing Solution\n",
      "======================================================================\n",
      "\n",
      "1. Loading data...\n",
      "   Train: 75,000 | Test: 75,000\n",
      "   Price range: $0.13 - $2796.00\n",
      "   Price median: $14.00\n",
      "   Removing 1488 extreme outliers...\n",
      "\n",
      "2. Feature engineering...\n",
      "   Extracting advanced features...\n",
      "   Total features: 266\n",
      "\n",
      "3. Training with 5-Fold Cross-Validation...\n",
      "\n",
      "============================================================\n",
      "Fold 1/8\n",
      "============================================================\n",
      "Training XGBoost...\n",
      "\n",
      "Fold 1 XGBoost SMAPE: 50.69%\n",
      "\n",
      "============================================================\n",
      "Fold 2/8\n",
      "============================================================\n",
      "Training XGBoost...\n",
      "\n",
      "Fold 2 XGBoost SMAPE: 50.24%\n",
      "\n",
      "============================================================\n",
      "Fold 3/8\n",
      "============================================================\n",
      "Training XGBoost...\n",
      "\n",
      "Fold 3 XGBoost SMAPE: 50.11%\n",
      "\n",
      "============================================================\n",
      "Fold 4/8\n",
      "============================================================\n",
      "Training XGBoost...\n",
      "\n",
      "Fold 4 XGBoost SMAPE: 50.90%\n",
      "\n",
      "============================================================\n",
      "Fold 5/8\n",
      "============================================================\n",
      "Training XGBoost...\n",
      "\n",
      "Fold 5 XGBoost SMAPE: 49.91%\n",
      "\n",
      "============================================================\n",
      "Fold 6/8\n",
      "============================================================\n",
      "Training XGBoost...\n",
      "\n",
      "Fold 6 XGBoost SMAPE: 50.23%\n",
      "\n",
      "============================================================\n",
      "Fold 7/8\n",
      "============================================================\n",
      "Training XGBoost...\n",
      "\n",
      "Fold 7 XGBoost SMAPE: 50.30%\n",
      "\n",
      "============================================================\n",
      "Fold 8/8\n",
      "============================================================\n",
      "Training XGBoost...\n",
      "\n",
      "Fold 8 XGBoost SMAPE: 50.17%\n",
      "\n",
      "============================================================\n",
      "Overall CV SMAPE: 50.32%\n",
      "============================================================\n",
      "\n",
      "4. Preparing test features...\n",
      "   Extracting advanced features...\n",
      "   Total features: 266\n",
      "\n",
      "5. Making predictions...\n",
      "\n",
      "6. Creating submission...\n",
      "\n",
      "✓ Saved to 'test_out_xgboost.csv'\n",
      "\n",
      "Prediction stats:\n",
      "   Min: $1.75\n",
      "   Max: $145.96\n",
      "   Median: $13.75\n",
      "   Mean: $17.80\n",
      "\n",
      "======================================================================\n",
      "✓ COMPLETE! Expected test SMAPE: 50.3%\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "XGBoost-Only Product Price Prediction Solution\n",
    "\n",
    "Key Features:\n",
    "1. Advanced feature engineering with brand extraction\n",
    "2. Cross-validation for stability\n",
    "3. Better handling of different price ranges\n",
    "4. Single XGBoost model for faster training\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "def extract_advanced_features(df):\n",
    "    \"\"\"Advanced feature extraction with better price indicators\"\"\"\n",
    "    \n",
    "    features = pd.DataFrame()\n",
    "    text = df['catalog_content'].astype(str)\n",
    "    \n",
    "    # ========== PACK QUANTITY (Critical Feature) ==========\n",
    "    def extract_pack_qty(t):\n",
    "        patterns = [\n",
    "            r'pack\\s*of\\s*(\\d+)',\n",
    "            r'(\\d+)\\s*pack',\n",
    "            r'(\\d+)\\s*count',\n",
    "            r'count[:\\s]*(\\d+)',\n",
    "            r'(\\d+)\\s*(?:piece|pcs|units?)',\n",
    "            r'set\\s*of\\s*(\\d+)',\n",
    "            r'(\\d+)\\s*in\\s*1',\n",
    "            r'quantity[:\\s]*(\\d+)',\n",
    "        ]\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, t.lower())\n",
    "            if match:\n",
    "                qty = int(match.group(1))\n",
    "                if qty > 0 and qty <= 1000:\n",
    "                    return qty\n",
    "        return 1\n",
    "    \n",
    "    features['pack_qty'] = text.apply(extract_pack_qty)\n",
    "    features['pack_qty_log'] = np.log1p(features['pack_qty'])\n",
    "    features['pack_qty_sqrt'] = np.sqrt(features['pack_qty'])\n",
    "    features['is_multi_pack'] = (features['pack_qty'] > 1).astype(int)\n",
    "    features['pack_tier'] = pd.cut(features['pack_qty'], \n",
    "                                    bins=[0, 1, 3, 6, 12, 24, 1000],\n",
    "                                    labels=[0, 1, 2, 3, 4, 5]).astype(int)\n",
    "    \n",
    "    # ========== WEIGHT EXTRACTION ==========\n",
    "    def extract_weight_grams(t):\n",
    "        total = 0\n",
    "        # Pounds\n",
    "        for match in re.finditer(r'(\\d+\\.?\\d*)\\s*(?:lb|pound)s?', t.lower()):\n",
    "            total += float(match.group(1)) * 453.592\n",
    "        # Ounces\n",
    "        for match in re.finditer(r'(\\d+\\.?\\d*)\\s*oz(?!one)', t.lower()):\n",
    "            total += float(match.group(1)) * 28.3495\n",
    "        # Kilograms\n",
    "        for match in re.finditer(r'(\\d+\\.?\\d*)\\s*kg', t.lower()):\n",
    "            total += float(match.group(1)) * 1000\n",
    "        # Grams\n",
    "        for match in re.finditer(r'(\\d+\\.?\\d*)\\s*g(?!\\w)', t.lower()):\n",
    "            total += float(match.group(1))\n",
    "        return total\n",
    "    \n",
    "    features['weight_g'] = text.apply(extract_weight_grams)\n",
    "    features['weight_log'] = np.log1p(features['weight_g'])\n",
    "    features['has_weight'] = (features['weight_g'] > 0).astype(int)\n",
    "    features['weight_per_pack'] = features['weight_g'] / features['pack_qty']\n",
    "    features['weight_per_pack_log'] = np.log1p(features['weight_per_pack'])\n",
    "    \n",
    "    # ========== VOLUME EXTRACTION ==========\n",
    "    def extract_volume_ml(t):\n",
    "        total = 0\n",
    "        # Liters\n",
    "        for match in re.finditer(r'(\\d+\\.?\\d*)\\s*l(?:iter)?s?(?!\\w)', t.lower()):\n",
    "            total += float(match.group(1)) * 1000\n",
    "        # Milliliters\n",
    "        for match in re.finditer(r'(\\d+\\.?\\d*)\\s*ml', t.lower()):\n",
    "            total += float(match.group(1))\n",
    "        # Gallons\n",
    "        for match in re.finditer(r'(\\d+\\.?\\d*)\\s*gal(?:lon)?s?', t.lower()):\n",
    "            total += float(match.group(1)) * 3785.41\n",
    "        # Fluid ounces\n",
    "        for match in re.finditer(r'(\\d+\\.?\\d*)\\s*fl\\.?\\s*oz', t.lower()):\n",
    "            total += float(match.group(1)) * 29.5735\n",
    "        return total\n",
    "    \n",
    "    features['volume_ml'] = text.apply(extract_volume_ml)\n",
    "    features['volume_log'] = np.log1p(features['volume_ml'])\n",
    "    features['has_volume'] = (features['volume_ml'] > 0).astype(int)\n",
    "    features['volume_per_pack'] = features['volume_ml'] / features['pack_qty']\n",
    "    features['volume_per_pack_log'] = np.log1p(features['volume_per_pack'])\n",
    "    \n",
    "    # ========== SIZE/DIMENSIONS ==========\n",
    "    def extract_dimensions(t):\n",
    "        dims = []\n",
    "        # 3D dimensions\n",
    "        for match in re.finditer(r'(\\d+\\.?\\d*)\\s*x\\s*(\\d+\\.?\\d*)\\s*x\\s*(\\d+\\.?\\d*)', t.lower()):\n",
    "            dims.extend([float(match.group(i)) for i in [1, 2, 3]])\n",
    "        # Individual measurements\n",
    "        for match in re.finditer(r'(\\d+\\.?\\d*)\\s*(?:inch|cm|mm|ft)', t.lower()):\n",
    "            dims.append(float(match.group(1)))\n",
    "        return dims\n",
    "    \n",
    "    features['max_dim'] = text.apply(lambda x: max(extract_dimensions(x)) if extract_dimensions(x) else 0)\n",
    "    features['dim_log'] = np.log1p(features['max_dim'])\n",
    "    features['has_dimensions'] = (features['max_dim'] > 0).astype(int)\n",
    "    \n",
    "    # ========== BRAND EXTRACTION (Important!) ==========\n",
    "    def extract_brand_strength(t):\n",
    "        # Premium brands indicator\n",
    "        premium_brands = ['apple', 'samsung', 'sony', 'nike', 'adidas', 'lego', \n",
    "                         'nestlé', 'loreal', 'dove', 'organic', 'natural']\n",
    "        score = sum(1 for brand in premium_brands if brand in t.lower())\n",
    "        \n",
    "        # Has a capitalized word at the start (likely brand)\n",
    "        if re.match(r'^[A-Z][a-z]+', t):\n",
    "            score += 2\n",
    "            \n",
    "        return score\n",
    "    \n",
    "    features['brand_strength'] = text.apply(extract_brand_strength)\n",
    "    \n",
    "    # ========== TEXT FEATURES ==========\n",
    "    features['text_len'] = text.str.len()\n",
    "    features['text_len_log'] = np.log1p(features['text_len'])\n",
    "    features['word_count'] = text.str.split().str.len()\n",
    "    features['word_count_log'] = np.log1p(features['word_count'])\n",
    "    features['avg_word_len'] = features['text_len'] / (features['word_count'] + 1)\n",
    "    features['digit_count'] = text.apply(lambda x: sum(c.isdigit() for c in x))\n",
    "    features['digit_ratio'] = features['digit_count'] / (features['text_len'] + 1)\n",
    "    features['upper_count'] = text.apply(lambda x: sum(c.isupper() for c in x))\n",
    "    features['upper_ratio'] = features['upper_count'] / (features['text_len'] + 1)\n",
    "    \n",
    "    # ========== PREMIUM/QUALITY INDICATORS ==========\n",
    "    premium_kw = ['premium', 'luxury', 'deluxe', 'professional', 'pro', 'organic',\n",
    "                  'natural', 'gourmet', 'artisan', 'exclusive', 'elite', 'designer',\n",
    "                  'imported', 'signature', 'collection', 'certified', 'authentic']\n",
    "    \n",
    "    features['premium_count'] = text.str.lower().apply(\n",
    "        lambda x: sum(1 for kw in premium_kw if kw in x)\n",
    "    )\n",
    "    \n",
    "    budget_kw = ['budget', 'value', 'affordable', 'economy', 'basic', 'cheap',\n",
    "                 'discount', 'clearance', 'sale']\n",
    "    \n",
    "    features['budget_count'] = text.str.lower().apply(\n",
    "        lambda x: sum(1 for kw in budget_kw if kw in x)\n",
    "    )\n",
    "    \n",
    "    # ========== CATEGORY INDICATORS ==========\n",
    "    categories = {\n",
    "        'electronics': ['electronic', 'digital', 'wireless', 'bluetooth', 'smart', 'usb', 'cable'],\n",
    "        'food': ['food', 'snack', 'coffee', 'tea', 'chocolate', 'candy', 'nutrition', 'protein'],\n",
    "        'beauty': ['beauty', 'cosmetic', 'makeup', 'skincare', 'lotion', 'shampoo', 'soap'],\n",
    "        'health': ['vitamin', 'supplement', 'health', 'medical', 'capsule', 'tablet'],\n",
    "        'baby': ['baby', 'infant', 'toddler', 'diaper', 'newborn', 'children'],\n",
    "        'pet': ['pet', 'dog', 'cat', 'animal', 'bird', 'fish'],\n",
    "        'home': ['home', 'kitchen', 'bedding', 'towel', 'furniture', 'decor'],\n",
    "        'clothing': ['shirt', 'pant', 'dress', 'wear', 'fashion', 'clothing'],\n",
    "        'toy': ['toy', 'game', 'puzzle', 'play', 'doll', 'action figure'],\n",
    "        'book': ['book', 'novel', 'paperback', 'hardcover', 'journal']\n",
    "    }\n",
    "    \n",
    "    for cat, keywords in categories.items():\n",
    "        features[f'cat_{cat}'] = text.str.lower().apply(\n",
    "            lambda x: int(any(kw in x for kw in keywords))\n",
    "        )\n",
    "    \n",
    "    # Category with pack interaction\n",
    "    for cat in categories.keys():\n",
    "        features[f'{cat}_pack'] = features[f'cat_{cat}'] * features['pack_qty_log']\n",
    "    \n",
    "    # ========== MATERIAL INDICATORS ==========\n",
    "    expensive_materials = {\n",
    "        'gold': 10, 'platinum': 10, 'diamond': 10, 'silver': 8,\n",
    "        'leather': 7, 'silk': 8, 'cashmere': 9, 'wool': 6,\n",
    "        'stainless steel': 6, 'titanium': 8, 'ceramic': 5\n",
    "    }\n",
    "    \n",
    "    cheap_materials = {\n",
    "        'plastic': 2, 'rubber': 2, 'paper': 1, 'cardboard': 1\n",
    "    }\n",
    "    \n",
    "    features['expensive_material_score'] = text.str.lower().apply(\n",
    "        lambda x: sum(weight for mat, weight in expensive_materials.items() if mat in x)\n",
    "    )\n",
    "    \n",
    "    features['cheap_material_score'] = text.str.lower().apply(\n",
    "        lambda x: sum(weight for mat, weight in cheap_materials.items() if mat in x)\n",
    "    )\n",
    "    \n",
    "    features['material_price_indicator'] = (\n",
    "        features['expensive_material_score'] - features['cheap_material_score']\n",
    "    )\n",
    "    \n",
    "    # ========== NUMBER EXTRACTION ==========\n",
    "    def extract_numbers(t):\n",
    "        nums = re.findall(r'\\d+\\.?\\d*', t)\n",
    "        return [float(n) for n in nums if 0 < float(n) < 10000]\n",
    "    \n",
    "    features['num_count'] = text.apply(lambda x: len(extract_numbers(x)))\n",
    "    features['max_num'] = text.apply(lambda x: max(extract_numbers(x)) if extract_numbers(x) else 0)\n",
    "    features['min_num'] = text.apply(lambda x: min(extract_numbers(x)) if extract_numbers(x) else 0)\n",
    "    features['mean_num'] = text.apply(lambda x: np.mean(extract_numbers(x)) if extract_numbers(x) else 0)\n",
    "    features['std_num'] = text.apply(lambda x: np.std(extract_numbers(x)) if len(extract_numbers(x)) > 1 else 0)\n",
    "    \n",
    "    # ========== ADVANCED INTERACTIONS ==========\n",
    "    # Total content (weight or volume)\n",
    "    features['total_content'] = features['weight_g'] + features['volume_ml']\n",
    "    features['total_content_log'] = np.log1p(features['total_content'])\n",
    "    \n",
    "    # Price indicators\n",
    "    features['bulk_indicator'] = features['pack_qty'] * features['total_content_log']\n",
    "    features['premium_bulk'] = features['premium_count'] * features['bulk_indicator']\n",
    "    features['quality_weight'] = features['brand_strength'] * features['weight_log']\n",
    "    \n",
    "    # Category-specific features\n",
    "    features['food_weight'] = features['cat_food'] * features['weight_log']\n",
    "    features['electronics_premium'] = features['cat_electronics'] * features['premium_count']\n",
    "    features['beauty_volume'] = features['cat_beauty'] * features['volume_log']\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "class XGBoostPricePredictionModel:\n",
    "    \"\"\"XGBoost-only model with cross-validation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer(\n",
    "            max_features=4000,\n",
    "            ngram_range=(1, 3),\n",
    "            min_df=3,\n",
    "            max_df=0.9,\n",
    "            strip_accents='unicode',\n",
    "            sublinear_tf=True\n",
    "        )\n",
    "        self.svd = TruncatedSVD(n_components=200, random_state=42)\n",
    "        self.scaler = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "        self.models = []\n",
    "        \n",
    "    def prepare_features(self, df, is_train=True):\n",
    "        \"\"\"Prepare features with better preprocessing\"\"\"\n",
    "        \n",
    "        # Text cleaning\n",
    "        cleaned_text = df['catalog_content'].astype(str).apply(\n",
    "            lambda x: re.sub(r'[^\\w\\s]', ' ', x.lower()).strip()\n",
    "        )\n",
    "        \n",
    "        # TF-IDF\n",
    "        if is_train:\n",
    "            tfidf_feat = self.tfidf.fit_transform(cleaned_text)\n",
    "            text_feat = self.svd.fit_transform(tfidf_feat)\n",
    "        else:\n",
    "            tfidf_feat = self.tfidf.transform(cleaned_text)\n",
    "            text_feat = self.svd.transform(tfidf_feat)\n",
    "        \n",
    "        # Manual features\n",
    "        print(\"   Extracting advanced features...\")\n",
    "        manual_feat = extract_advanced_features(df)\n",
    "        \n",
    "        # Combine\n",
    "        all_feat = np.hstack([text_feat, manual_feat.values])\n",
    "        \n",
    "        # Scale\n",
    "        if is_train:\n",
    "            all_feat = self.scaler.fit_transform(all_feat)\n",
    "        else:\n",
    "            all_feat = self.scaler.transform(all_feat)\n",
    "        \n",
    "        print(f\"   Total features: {all_feat.shape[1]}\")\n",
    "        return all_feat\n",
    "    \n",
    "    def train_with_cv(self, X, y, n_folds=5):\n",
    "        \"\"\"Train XGBoost with cross-validation\"\"\"\n",
    "        \n",
    "        kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "        \n",
    "        oof_preds = np.zeros(len(y))\n",
    "        xgb_models = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Fold {fold}/{n_folds}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            X_tr, X_val = X[train_idx], X[val_idx]\n",
    "            y_tr, y_val = y[train_idx], y[val_idx]\n",
    "            \n",
    "            # Log transform target\n",
    "            y_tr_log = np.log1p(y_tr)\n",
    "            y_val_log = np.log1p(y_val)\n",
    "            \n",
    "            # XGBoost\n",
    "            print(\"Training XGBoost...\")\n",
    "            xgb_model = xgb.XGBRegressor(\n",
    "                n_estimators=2000,\n",
    "                learning_rate=0.02,\n",
    "                max_depth=10,\n",
    "                min_child_weight=3,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                reg_alpha=1.0,\n",
    "                reg_lambda=1.0,\n",
    "                random_state=42,\n",
    "                verbosity=0\n",
    "            )\n",
    "            xgb_model.fit(\n",
    "                X_tr, y_tr_log,\n",
    "                eval_set=[(X_val, y_val_log)],\n",
    "                verbose=False\n",
    "            )\n",
    "            oof_preds[val_idx] = np.expm1(xgb_model.predict(X_val))\n",
    "            xgb_models.append(xgb_model)\n",
    "            \n",
    "            # Fold SMAPE\n",
    "            fold_smape = self.calculate_smape(y_val, oof_preds[val_idx])\n",
    "            print(f\"\\nFold {fold} XGBoost SMAPE: {fold_smape*100:.2f}%\")\n",
    "        \n",
    "        # Store models\n",
    "        self.models = xgb_models\n",
    "        \n",
    "        # Calculate overall CV score\n",
    "        cv_smape = self.calculate_smape(y, oof_preds)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Overall CV SMAPE: {cv_smape*100:.2f}%\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        return cv_smape\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using averaged XGBoost models\"\"\"\n",
    "        \n",
    "        # Get predictions from all folds\n",
    "        preds = np.mean([np.expm1(model.predict(X)) for model in self.models], axis=0)\n",
    "        preds = np.clip(preds, 0.1, 3000)\n",
    "        \n",
    "        return preds\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_smape(y_true, y_pred):\n",
    "        \"\"\"SMAPE metric\"\"\"\n",
    "        denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "        diff = np.abs(y_true - y_pred)\n",
    "        return np.mean(diff / (denominator + 1e-10))\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution\"\"\"\n",
    "    \n",
    "    DATASET_FOLDER = './dataset/'\n",
    "    OUTPUT_FILE = 'test_out_xgboost.csv'\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"XGBoost-Only Product Pricing Solution\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Load data\n",
    "    print(\"\\n1. Loading data...\")\n",
    "    train_df = pd.read_csv(os.path.join(DATASET_FOLDER, 'train.csv'))\n",
    "    test_df = pd.read_csv(os.path.join(DATASET_FOLDER, 'test.csv'))\n",
    "    \n",
    "    print(f\"   Train: {len(train_df):,} | Test: {len(test_df):,}\")\n",
    "    print(f\"   Price range: ${train_df['price'].min():.2f} - ${train_df['price'].max():.2f}\")\n",
    "    print(f\"   Price median: ${train_df['price'].median():.2f}\")\n",
    "    \n",
    "    # Remove extreme outliers\n",
    "    q1 = train_df['price'].quantile(0.01)\n",
    "    q99 = train_df['price'].quantile(0.99)\n",
    "    mask = (train_df['price'] >= q1) & (train_df['price'] <= q99)\n",
    "    print(f\"   Removing {(~mask).sum()} extreme outliers...\")\n",
    "    train_df = train_df[mask].reset_index(drop=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = XGBoostPricePredictionModel()\n",
    "    \n",
    "    # Prepare features\n",
    "    print(\"\\n2. Feature engineering...\")\n",
    "    X_train = model.prepare_features(train_df, is_train=True)\n",
    "    y_train = train_df['price'].values\n",
    "    \n",
    "    # Train with CV\n",
    "    print(\"\\n3. Training with 5-Fold Cross-Validation...\")\n",
    "    cv_score = model.train_with_cv(X_train, y_train, n_folds=5)\n",
    "    \n",
    "    # Prepare test features\n",
    "    print(\"\\n4. Preparing test features...\")\n",
    "    X_test = model.prepare_features(test_df, is_train=False)\n",
    "    \n",
    "    # Predict\n",
    "    print(\"\\n5. Making predictions...\")\n",
    "    test_predictions = model.predict(X_test)\n",
    "    \n",
    "    # Save\n",
    "    print(\"\\n6. Creating submission...\")\n",
    "    submission = pd.DataFrame({\n",
    "        'sample_id': test_df['sample_id'],\n",
    "        'price': test_predictions\n",
    "    })\n",
    "    submission.to_csv(OUTPUT_FILE, index=False)\n",
    "    \n",
    "    print(f\"\\n✓ Saved to '{OUTPUT_FILE}'\")\n",
    "    print(f\"\\nPrediction stats:\")\n",
    "    print(f\"   Min: ${test_predictions.min():.2f}\")\n",
    "    print(f\"   Max: ${test_predictions.max():.2f}\")\n",
    "    print(f\"   Median: ${np.median(test_predictions):.2f}\")\n",
    "    print(f\"   Mean: ${np.mean(test_predictions):.2f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"✓ COMPLETE! Expected test SMAPE: {cv_score*100:.1f}%\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
